# Deep Learning(Keras)

* 활성화 함수가 필요한 이유(p.110) : **선형 층을 깊게 쌓아도 여전히 하나의 선형 연산이기 때문에** 층을 여러 개로 구성하는 장점이 없음. 따라서 **가설 공간을 풍부하게 만들기 위해**(확장시키기 위해) **비선형성을 갖는 활성화 함수**를 추가
* 테스트 데이터를 정규화할 때(scaling) 사용한 값이 훈련 데이터에서 계산한 값을 활용함. 훈련 데이터에서 학습한 정보를 활용하기 위함과 동시에 테스트 데이터의 정보를 완전히 독립시키기 위함. 이를 위해 KFold 교차 검증 시에, scaling 작업이 미리 되어 있으면 안되고, 교차 검증 안으로 들어가서 진행해야 함. 이 때, sklearn의 pipeline 유용
* 출력 클래스가 여러 개일 경우, 은닉층의 output은 최소 출력 클래스 이상이어야 정보의 병목 현상을 피할 수 있음
* 정규화 목적 : 데이터는 작은 값(대부분 0~1)을 취하며, 균일해야 함(scaling). 그렇지 않으면, **업데이트할 그래디언트가 커져 네트워크가 수렴하는 것을 방해**하기 때문
* Imputation 진행 시, 훈련 데이터의 특정 피쳐에서 결측을 A(0, 평균, 중간)값으로 처리했다면 테스트 데이터에서도 동일한 값으로 결측을 처리 해야함. 따라서 KFold 교차 검증 시에 미리 Inputation이 되어 있으면 안되고, 교차 검증 안에서 진행해야 함(scaling과 마찬가지)
* 특정 피쳐의 결측이 테스트 데이터에만 있다면, 고의적으로 훈련 데이터의 특정 피쳐를 고의적으로 결측으로 만들어야 네트워크가 결측을 무시할 수 있도록 학습할 수 있음
* overfitting을 막는 가장 좋은 방법은 많은 훈련 데이터를 모으는 것. 차선책은 모데링 수용할 수 있는 정보에 제약을 가하는 것 - **적은 수의 패턴만 기억하게 만들어서 가장 중요한 패턴에 집중 : 규제(regularization)**
* 적절한 모델의 크기(층의 수, 층의 유닛 수)를 찾는 일반적인 작업 흐름은 **비교적 적은 수의 층과 파라미터로 시작해서 검증 손실(validation loss)이 감소되기 시작할 때까지 층이나 유닛의 수를 늘리는 것**. 마법같은 공식은 없음
* 드롭아웃 등을 사용해 **과대적합을 줄이는 기본 단계를 거친 후 과대적합이 일어날 때 까지 네트워크의 용량을 늘리는 것**이 좋다. 너무 많이 과대적합되지 않는 한 아직 충분한 용량에 도달한 것이 아님
* 비지도 학습 : 어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾는 학습 방법. ex) 차원 축소, 군집화
* 자기 지도 학습 : 지도 학습이지만(레이블을 필요로하지만) 보통 경험적인 알고리즘(heuristic algorithm)을 사용해서 입력 데이터로부터 타깃을 생성한다 ex) autoencoder
* 하이퍼파라미터 튜닝도 결국 **학습**이다. 따라서 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증 세트로 모델을 직접 훈련하지 않더라도 빠르게 검증 세트에 과대적합 될 수 있다
* K-fold 검증으로 하이퍼라라미터 튜닝을 한 이후에 train과 validation용 데이터를 활용해 최종 모델을 훈련한다
* 특성 공학이 신경망 모델에 필요한 이유는 첫째, 좋은 특성은 적은 자원을 사용하여 문제를 풀 수 있게 한다. 둘째, 좋은 특성은 더 적은 데이터로 문제를 풀 수 있게 한다
* 평가 지표
  * 클래스 분포가 균일한 분류 문제 : ROC AUC
  * 클래스 분포가 균일하지 않은 분류 문제 : 정밀도, 재현율
  * 랭킹 및 다중 레이블 문제 : 평균 정밀도(average_precision_score())
* 딥러닝에서 **손실 함수는 주어진 미니 배치 데이터에서 계산 가능해야 하고, 미분 가능해야 한다.** 따라서 ROC AUC는 미분 불가능하기 때문에 손실 함수로 사용하지 않음(역전파 알고리즘을 사용하여 네트워크 훈련 불가능)
* Optimizer
  * rmsprop, adam : learning rate = 0.001(기본)
  * sgd, adagrad : learning rate = 0.01(기본)
* 그래프로 손실과 정확도를 함께 나타냈을 때, <u>손실이 감소되지 않더라도 정확도는 향상될 수 있다. 그래프는 개별적인 손실 값의 평균을 그린 것이지만, 정확도에 영향을 미치는 것은 손실 값의 분포이지 평균이 아니기 때문이다</u>
* 다중 레이블 다중 분류 : 하나의 샘플이 여러 개의 클래스에 속할 수 있는 경우. 예를 들어 한 이미지에 강아지와 고양이가 둘 다 있다면 강아지 레이블과 고양이 레이블 모두 할당해야 한다. 마지막 Dense 층이 클래스 개수만큼 유닛을 가져야 하고, 시그모이드 활성화 함수를 사용해야 한다. 손실로는 binary_crossentropy를 사용하며 타깃은 k-hot-encoding 적용한다(sklearn의 MultilLabelBinarizer 클래스 사용)

</br>

# CNN

* FCN 층과 합성곱 층 사이의 근본적인 차이는 **Dense 층은 입력 특성 공간에 있는 전역 패턴(예를 들어 MNIST 숫자 이미지에서는 모든 픽셀에 걸친 패턴)을 학습하지만 합성곱 층을 지역 패턴을 학습한다**
  * **학습된 패턴은 평행 이동 불변성을 가짐.** FCN은 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 한다.
  * 컨브넷은 패턴의 공간적 계층 구조를 학습할 수 있음(첫 번째 층은 작은 지역 패턴을 학습하고, 두 번째 층은 첫 번째 층의 특성으로 구성된 더 큰 패턴을 학습)
* 응답 맵(response map)은 입력의 각 위치에서 한 패턴의 존재에 대한 2D맵(입력 값이 단일 필터 거친 것)
* 합성곱 커널은 합성곱 층의 필터를 하나의 행렬로 합친 것 
* 합성곱 동작 방식 : 입력 특성 맵 > 입력 패치(보통 3x3 or 5x5 활용) > 변환된 패치 > 출력 특성 맵
* 특성 맵의 깊이는 네트워크에서 점진적으로 증가하지만, 특성 맵의 크기는 감소한다. 이는 거의 모든 conv net에서 볼 수 있는 전형적인 패턴이다
* **패딩(padding)** : 입력과 동일한 높이와 너비를 가진 출력 특성 맵을 얻고 싶을 경우 사용한다
* **Max Pooling** : 합성곱과 개념적으로 비슷하지만 추출한 패치에 학습된 선형 변환(합성곱 커널)을 적용하는 대신 하드코딩된 최댓값 추출 연산을 사용한다. 역할은 강제적으로 특성 맵을 **다운샘플링** 하여 과대적합을 줄이기 위함이다.
* Max pooling을 하지 않는다면 : 최종 특성 맵에는 입력에 대한 정보만 담고 있어, 고수준 패턴 학습하기 어렵다. 또한 **가중치가 많아져 과대적합 일어난다**
* **Data Augmentation은 이미지를 다룰 때 모델 일반화를 위해 주로 사용된다. 검증 및 테스트 데이터 셋은 증식되어서는 안 된다**
* 사전 훈련된 CNN 사용 시, 합성곱 층만 재사용하고, 분류기 층(FCN 층)은 재사용하지 않는다(분류기는 전체 사진에 어떤 클래스가 존재할 확률에 관한 정보만 담고 있으므로, 새로운 데이터 샘플로 학습된 경우 의미가 없음)
* <u>사전 훈련된 모델 사용</u>
  * 데이터 증식을 사용하지 않는 빠른 특성 추출 : 새로운 데이터셋에서 합성곱 기반 층을 실행하고 출력을 넘파이 배열로 디스크에 저장한 뒤에 이 데이터를 독립된 완전 연결 분류기에 입력으로 사용한다. 데이터 증식(augmentation) 사용 할 수 없다. 빠르다
  * 데이터 증식을 사용한 특성 추출 : 미리 학습된 모델 위에 Dense층을 쌓아 확장한 뒤에 입력 데이터에서 엔드투-엔드로 전체 모델을 실행한다. 데이터 증식 사용할 수 있다. 느리다. **주의 해야 할 점은 미리 학습된 모델의 가중치는 변경되어서는 안되고 Dense 층 가중치만 새로 훈련되어야 한다는 점이다**
    * 미세 조정 : 특성 추출에 사용했던 동결 모델의 상위 층 몇 개를 동결에서 해제하고 모델에 새로 추가한 층과 함께 훈련한다. **이 때 분류기가 미리 훈련된 후에 합성곱 기반의 상위 층을 미세 조정해야 한다.** 이유는 분류기가 미리 훈련되지 않으면 훈련되는 동안 너무 큰 오차 신호가 네트워크에 전파되어 미세 조정될 층들이 사전에 학습한 표현들을 망가뜨릴 수 있기 때문이다. **보통 합성곱 기반 층에서 최상위 2~3개의 층만 미세 조정하는 것이 좋다**

</br>

# 텍스트와 시퀀스 처리

* 토큰은 텍스트를 나누는 단위(단어, 문자, n-그램)을 의미한다
* 단어 n-그램은 문장에서 추출한 N개의 연속된 단어 그룹이며, 같은 개념이 단어 대신 문자에도 적용될 수 있다
* <u>토큰의 집합을 BoW(Bag-of-Words)라고 한다(순서가 없는 토큰화)</u>
* Embedding은 특정 단어를 나타내는 정수 인덱스를 밀집 벡터로 매핑하는 딕셔너로리로 이해하는 것이 좋다. 멀리 떨어진 위치에 임베딩된 단어 의미는 서로 다른 반면에 비슷한 단어들은 가까이 임베딩된다. 이러한 임베딩 방식은 저차원의 실수형 벡터이다(밀집 벡터). 입력으로 (samples, sequence_length)인 2D 정수 텐서를 받고, (samples, sequence_length, embedding_dimensionality)인 3D 실수형 텐서를 반환한다
  * 사전 훈련된 단어 임베딩 : Word2vec(2013), Glove(2014)..."임베딩은 훈련된다"
* <u>순서 : 토근화 - 임베딩 처리 - 임베딩 처리 값을 임베딩 레이어에 입력</u>

</br>

# RNN

* LSTM 셀(층 또는 뉴런)의 역할은 바로 과거 정보를 나중에 다시 주입하여 그래디언트 소실 문제를 해결하는 것
* SimpleRNN은 이전 셀의 출력이 다음 셀의 입력으로 활용되는 데 반해 **LSTM은 이동 상태에 대한 정보가 추가적으로 다음 셀에 활용된다**
* <u>순환 네트워크에 적절하게 드롭아웃을 사용하는 방법은 타임스텝마다 랜덤하게 드롭아웃 마스크를 바꾸는 것이 아니라 **동일한** 드롭아웃 마스크(동일한 유닛의 드롭 패턴)를 모든 타임스텝에 적용하는 것이다</u>
* 드롭아웃으로 규제된 네트워크는 언제나 완전히 수렴하는 데 더 오래 걸린다. 에포크를 늘려 네트워크를 훈련한다
* 기본적인 GRU 층은 먼 과거보다 최근 내용을 잘 기억한다
* 양방향 RNN은 자연어 처리에서 훨씬 좋은 성능을 낸다. 입력 시퀀스를 양쪽 방향으로 바라보기 때문에 드러나지 않은 다양한 표현을 얻어 시간 순서대로 처리할 때 놓칠 수 있는 패턴을 잡아낸다
* 자연어 처리에서 순환 어텐션(attention), 시퀀스 마스킹(sequence masking) 살펴 보기

* 1D CNN도 특정 시퀀스 처리 문제에 사용된다. 일반적으로 계산 비용이 훨씬 적다. 하지만 타임스텝의 순서에 민감하지 않다(처음의 데이터와 나중의 데이터가 같은 의미를 가짐. 예를 들어 문장 번역에서 처음 단어는 나중의 단어와 동일한 의미를 같지만, 온도 예측에서는 처음 온도보다 나중의 온도가 더 큰 의미를 가질 수 있음)
* 1D CNN + RNN을 이용하면 수 많은 스텝을 가진 시퀀스를 다룰 때 특별히 도움된다. CNN이 긴 입력 시퀀스를 더 짧은 고수준 특성의 시퀀스로 변환하고, 추출된 특성의 시퀀스는 RNN 파트의 입력이 된다

</br>

# 고급 도구

* 다중 출력 모델에서 훈련하려면 네트워크 출력마다 다른 손실 함수를 지정해야 한다. 그리고 각각의 손실들을 하나의 값으로 합쳐야 하는데 가장 간단한 방법은 모두 더하는 것

  ```python
  # 다중 분류에서 타깃이 one-hot-encoding 되어 있다면 loss는 categorical_crossentropy이고, 정수 숫자라면 sparse_categorical_crossentropy로 손실을 사용한다
  model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])
  ```

  손실 값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화하는데, 그 결과 다른 작업들은 손해를 입는다. 특히 손실 값의 스케일이 다를 때 그러하며 이를 위해 손실 값이 최종 손실에 기여하는 수준을 지정할 수 있다

  ```python
  model.compile(optimizer='rmsprop',
                loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],
                loss_weights=[0.25, 1., 10.])
  ```

* 층 객체를 여러 번 재사용하여 층 가중치를 공유 할 수 있다. 층 객체를 두 번 호출하면 새로운 층 객체를 만들지 않고 각 호출에 동일한 가중치를 재사용한다. 아래의 코드를 샴 LSTM 또는 공유 LSTM이라고 부른다

  ```python
  from keras import layers
  from keras import Input
  from keras.models import Model
  
  lstm = layers.LSTM(32)
  left_input = Input(shape=(None, 128))
  left_output = lstm(left_input)
  
  right_input = Input(shape=(None, 128))
  right_output = lstm(right_output)
  
  merged = layers.concatenate([left_output, right_output], axis=-1)
  predictions = layers.Dense(1, activation='sigmoid')(merged)
  
  # 모델 객체를 만들고 훈련한다. 이런 모델을 훈련하면 LSTM 층의 가중치는 양쪽 입력을 바탕으로 업데이트된다
  model = Model([left_input, right_output], predictions)
  model.fit([left_output, right_output], tagets)
  ```

* 콜백을 사용해 모델이 훈련하는 동안 모델의 상태와 성능에 대한 모든 정보에 접근하여 훈련 중지, 모델 저장, 가중치 적재 또는 모델 상태 변경 등을 처리할 수 있다

  * 모델 체크포인트 저장 : 훈련하는 동안 어떤 지점에서 모델의 현재 가중치 저장
  * 조기 종료 : 검증 손실이 더 이상 향상되지 않을 때 훈련을 중지(가장 좋은 모델로)
  * 하이퍼파라미터 값을 동적으로 조정 : 옵티마이저의 학습률 같은 경우
  * 훈련과 검증 지표를 로그에 기록하거나 모델이 학습한 표현이 업데이트 될 때마다 시각화(progress bar)

  </br>

  ### ModelCheckpoint, EarlyStopping

  ```python
  import keras
  
  callbacks_list = [	# list로 전달하면 여러 개의 callback 사용 가능
    keras.callbacks.EarlyStopping(	# 성능 향상이 멈추면 훈련을 중지
      monitor='val_acc',	# 검증 정확도를 모니터링한다
      patience=1,	# 1 epoch보다 더 길게 (즉 2 epoch 동안) 정확도가 향상되지 않으면 훈련 중지
    ),
    keras.callbacks.ModelCheckpoint(
      filepath='my_model.h5',
      monitor='val_loss',
      save_best_only=True,	# val_loss가 좋아지지 않으면 모델 파일을 덮어쓰지 않고, 가장 좋은 모델 저장
    )
  ]
  
  mopdel.complie(optimizer='rmsprop',
                 loss='binary_crossentropy',
                 metrics=['acc'])	# 정확도를 모니터링하므로 모델 지표에 포함되어 있어야 한다
  
  model.fit(x, y,
            epochs=10,
            batch_size=32,
            callbacks=callbacks_list,
            validation_data=(x_val, y_val))
  ```

  </br>

  ### ReduceLROnPlateau

  검증 손실이 향상되지 않을 때 학습률을 작게 할 수 있다

  ```python
  callbacks_list = [
    keras.callbacks.ReduceLROnPlateau(
      monitor='val_loss',	# 검증 손실을 모니터링한다
      factor=0.1,	# 콜백이 호출 될 때 학습률을 10배로 줄인다
      patiene=10,	# 검증 손실이 10 epoch 동안 좋아지지 않으면 콜백이 호출된다
    )
  ]
  
  model.fit(x, y,
            batch_size=32,
            callbacks=callbacks_list,
            validation_data=(x_val, y_val))
  ```

* 데이터는 모델에 들어가기 전 뿐만 아니라 네트워크에서 일어나는 모든 변환 후에도 고려되어야 한다. **배치 정규화는 층의 한 종류로서 훈련하는 동안 평균과 분산이 바뀌더라도 이에 적응하여 데이터를 정규화 한다.** 입력과 출력의 분포를 유지하도록 도와주므로 잔차 연결과 매우 흡사하게 그래디언트의 전파를 도와줄 수 있다. **결국 더 깊은 네트워크를 구성할 수 있다.** 일반적으로 합성곱이나 완전 연결 층 다음에 사용한다. 배치 재정규화, 자기 정규화 신경망 개념도 있으니 참고

* <u>깊이별 분리 합성곱은 공간 특성의 학습과 채널 방향 특성의 학습을 분리하는 효과를 나타낸다. 입력에서 공간상 위치는 상관관계가 크지만 채널별로는 매우 독립적이라고 가정하다면 타당하다. 일반 합성곱보다 더 효율적으로 표현을 학습하기 때문에 성능이 더 좋은 모델 만들 수 있다.</u>

* 하이퍼파라미터 튜닝 방법으로는 베이지안 최적화, 유전 알고리즘(genetic algorithms), 랜덤 탐색, coarse to fine search이 있다. 랜덤 탐색 사용시 케라스의 경우 keras.wrappers.scikit_learn 모듈 아래에 있는 KerasClassifier와 KerasRegressor 클래스를 이용하면 사이킷런의 RandomizedSearchCV를 수행할 수 있다. 베이지안 최적화 방법 중 하나는 Hyperopt 라이브러리 활용. **하이퍼파라미터 튜닝시 가장 큰 이슈는 검증 데이터 세트에 과대적합될 수 있다는 점이다.** 아래 라이브러리도 있으니 참고

  * Hyperas
  * Auto-Keras
  * TPOT

* 앙상블의 각 모델의 가중치를 찾기 위해 랜덤 서치나 넬더-미드(Nelder-Mead) 방법 같은 간단한 최적화 알고리즘을 사용할 수 있다. 앙상블의 핵심은 모델의 다양성이다. 따라서 가능한 최대한 다르면서 좋은 모델들을 앙상블한다. 특정 모델이 성능이 특별히 안좋더라도 앙상블 결과는 그 특정 모델 덕분에 더 좋아질 수 있다. 딥러닝과 얕은 모델(트리 기반 모델 또는 선형 모델)의 조화가 일반적으로 좋다.